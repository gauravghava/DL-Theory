{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj4sKYTUDdam/5gG9ymiBU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirtiKousik/DL_Theory_Assignments_iNeuron/blob/main/DL_Theory_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?"
      ],
      "metadata": {
        "id": "sQnUTOydQ1Cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TensorFlow is a powerful open-source software library for numerical computation and large-scale machine learning, developed by Google Brain Team. \n",
        "- Its main features include dataflow and differentiable programming across a range of platforms, the ability to perform automatic differentiation, and support for distributed computing. \n",
        "- Some other popular Deep Learning libraries are PyTorch, Caffe, and Theano."
      ],
      "metadata": {
        "id": "vhTLeuaLRDCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?"
      ],
      "metadata": {
        "id": "8WvOQQ2hRIEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TensorFlow is not a drop-in replacement for NumPy. TensorFlow is a deep learning framework, while NumPy is a library for numerical computing in Python. The main differences between the two are:\n",
        "\n",
        "    - Purpose: TensorFlow is designed specifically for deep learning and large-scale machine learning, while NumPy is designed for numerical computing and array operations.\n",
        "\n",
        "    - Data Structure: TensorFlow uses tensors (multi-dimensional arrays) as its main data structure, while NumPy uses ndarrays. TensorFlow tensors can be processed and transformed using the TensorFlow graph computations, while NumPy arrays are processed using traditional array operations.\n",
        "\n",
        "    - Performance: TensorFlow provides high performance through parallel computation on multiple GPUs or CPUs, while NumPy is limited to single-threaded execution on a single CPU.\n",
        "\n",
        "    - Functionality: TensorFlow provides a comprehensive set of tools for building, training, and deploying deep learning models, while NumPy provides a basic set of mathematical and numerical functions for array operations."
      ],
      "metadata": {
        "id": "CMQPJLrDRbaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
      ],
      "metadata": {
        "id": "zraM2Y7DRhHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- No, the results of tf.range(10) and tf.constant(np.arange(10)) are not the same. tf.range(10) returns a TensorFlow tensor representing a sequence of numbers from 0 to 9, whereas tf.constant(np.arange(10)) returns a TensorFlow tensor initialized with the NumPy array np.arange(10), which is also a sequence of numbers from 0 to 9. However, the former is created dynamically during the computation, while the latter is a constant value that is stored in memory."
      ],
      "metadata": {
        "id": "Fg-qMWcrRvtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_range = tf.range(10)\n",
        "np_arange = np.arange(10)\n",
        "tf_constant = tf.constant(np_arange)\n",
        "\n",
        "print(\"tf.range: \", tf_range)\n",
        "print(\"np.arange: \", np_arange)\n",
        "print(\"tf.constant: \", tf_constant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scr5d05oQ4D5",
        "outputId": "93f4ed21-b049-4043-e799-d35600f01a5e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.range:  tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
            "np.arange:  [0 1 2 3 4 5 6 7 8 9]\n",
            "tf.constant:  tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Can you name six other data structures available in TensorFlow, beyond regular tensors?"
      ],
      "metadata": {
        "id": "7yo61gtQSYLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Six other data structures available in TensorFLow beyond regular tensors are:\n",
        "    - SparseTensor: used to represent sparse data, to reduce memory usage and speed up computation\n",
        "    - RaggedTensor: used to represent arrays of arrays with different lengths, similar to a nested list or nested array\n",
        "    - TensorArray: a dynamic array, used for building recurrent neural networks or other dynamic models\n",
        "    - Dataset: used to represent a sequence of elements, that can be transformed and processed in parallel\n",
        "    - EagerTensor: used to represent tensors with an eager execution mode, allowing for faster debugging and easier interaction with other Python libraries\n",
        "    - TensorSpec: used to specify the shape, dtype, and structure of a tensor, for use in building complex models and executing them in a low-level API."
      ],
      "metadata": {
        "id": "HIODqj-8SoAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?"
      ],
      "metadata": {
        "id": "uvxGmskLSn7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In TensorFlow's Keras API, you can define a custom loss function by either writing a function or subclassing the keras.losses.Loss class.\n",
        "\n",
        "- Using a function is suitable when the loss calculation can be written in a simple and straightforward manner using basic mathematical operations. The function should take two arguments, the true labels and the predictions, and return a scalar tensor representing the loss value.\n",
        "\n",
        "- On the other hand, subclassing the Loss class is a good choice when the loss calculation involves multiple inputs, auxiliary variables, custom training loops, or other more complex logic. The loss calculation can be implemented in the call method of the loss class, which takes two arguments and returns the loss value.\n",
        "\n",
        "- In general, if the loss calculation is simple, writing a function is a more straightforward and readable option, while subclassing Loss allows for more flexibility and control in complex cases."
      ],
      "metadata": {
        "id": "SdZANXPXTH9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?"
      ],
      "metadata": {
        "id": "lIk9GfztTME1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The choice between defining a custom metric as a function or a subclass of keras.metrics.Metric depends on the requirements and complexity of the metric.\n",
        "\n",
        "- If the metric is simple and only requires basic computation, such as mean squared error, it can be defined as a function using the metrics module. The function takes the true values and predictions as input and returns a single scalar value.\n",
        "\n",
        "- If the metric requires additional state variables, for example, running sum or count, or if it needs to be implemented as a complex stateful operation, then it is recommended to define it as a subclass of keras.metrics.Metric. This subclass should implement the following methods: __init__ to set up any state variables, update_state to accumulate the values of interest, and result to return the final value of the metric.\n",
        "\n",
        "- In general, if you want to implement a complex custom metric, subclassing keras.metrics.Metric is the recommended option, while if you want to implement a simple custom metric, defining it as a function is the easier option."
      ],
      "metadata": {
        "id": "IwWtuDHtTXB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. When should you create a custom layer versus a custom model?"
      ],
      "metadata": {
        "id": "S4ACCpsDTUXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A custom layer should be created when you need to implement a reusable piece of a neural network, such as a specific activation function or a pooling operation. A custom layer should implement the call method, which is responsible for performing the computation, and should be compatible with other layers.\n",
        "\n",
        "- A custom model should be created when you need to assemble a complete neural network architecture, with multiple inputs and outputs and a shared or non-shared set of layers. A custom model should subclass the keras.models.Model class, implement the call method, and be compatible with all Keras functionality, such as training, evaluation, and prediction. Custom models allow you to build more complex models than are possible with the built-in layers and models.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CjoDFaUGTxNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. What are some use cases that require writing your own custom training loop?"
      ],
      "metadata": {
        "id": "z_1Ra0IKTv94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are several use cases that require writing your own custom training loop:\n",
        "\n",
        "    - Custom Gradient Computation: If you want to implement a custom gradient computation that is not supported by TensorFlow's automatic differentiation system, you can write your own training loop.\n",
        "\n",
        "    - Mixed Precision Training: If you want to use mixed precision training, where different parts of your model use different numerical precisions, you will need to write your own training loop.\n",
        "\n",
        "    - Multi-Task Learning: If you want to train a multi-task learning model, where multiple tasks are trained at the same time, you will need to write your own training loop.\n",
        "\n",
        "    - Multi-GPU Training: If you want to perform multi-GPU training, where the model is split across multiple GPUs, you will need to write your own training loop.\n",
        "\n",
        "    - Custom Early Stopping: If you want to implement custom early stopping criteria that are not supported by the standard TensorFlow APIs, you will need to write your own training loop.\n",
        "\n",
        "    - Debugging: If you want to understand the inner workings of a deep learning model, you can write your own training loop and insert debug information to help you understand what's going on."
      ],
      "metadata": {
        "id": "EImElTqdULML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
      ],
      "metadata": {
        "id": "tG3IEuUrT-Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Keras components can contain arbitrary Python code, but they must be able to be called from TensorFlow functions to work properly in a Keras model. It is recommended to wrap any custom code into TensorFlow operations, to ensure that the model is fully differentiable, and can be trained using gradient descent and backpropagation."
      ],
      "metadata": {
        "id": "4yjoK7SWUWzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. What are the main rules to respect if you want a function to be convertible to a TF Function?"
      ],
      "metadata": {
        "id": "MDQQxiQ6UTOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to make a function convertible to a TensorFlow Function, the following rules must be followed:\n",
        "\n",
        "    - The function must not contain any Python-level side effects like modifying a global variable or printing.\n",
        "\n",
        "    - The function must not return any Python-level objects, such as lists or dictionaries, but it can return tensors.\n",
        "\n",
        "    - The function must not contain any control flow statements (if statements, for loops, while loops, etc.).\n",
        "\n",
        "    - The function must take only tensors as input, and it must only produce tensors as output.\n",
        "\n",
        "    - All tensors must have a static shape (i.e., a shape that can be computed at graph construction time)."
      ],
      "metadata": {
        "id": "AWU-DsSZUmYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?"
      ],
      "metadata": {
        "id": "qKMamgrjUbRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A dynamic Keras model is a model that you can change its structure on the fly, during or after the model has been compiled. Some use cases that require creating a dynamic model include:\n",
        "\n",
        "    1. Model architecture with conditional branching: you might want to change the model structure based on input data or a specific condition.\n",
        "\n",
        "    2. Models with a variable number of inputs or outputs: you might need to dynamically add or remove inputs or outputs to the model based on the data being processed.\n",
        "\n",
        "    3. Ensemble models: you might want to build a combination of multiple models, where the combination is dynamic and depends on some conditions.\n",
        "\n",
        "- To create a dynamic model, you can use the functional API or the subclassing API, and instead of adding layers to the model with model.add(), you create the layers within a custom build method, and call it when you are ready to compile the model.\n",
        "\n",
        "- One reason not to make all models dynamic is that dynamic models are less optimized compared to static models and can lead to slower runtime performance. Static models are more optimized because TensorFlow can better analyze the graph structure and optimize computation. Therefore, it is advisable to use dynamic models only when necessary."
      ],
      "metadata": {
        "id": "ksozagg5Uz5t"
      }
    }
  ]
}