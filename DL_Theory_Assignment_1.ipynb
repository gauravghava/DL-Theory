{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtR62LbeATstjaVMz6a6tE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirtiKousik/DL_Theory_Assignments_iNeuron/blob/main/DL_Theory_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What is the function of a summation junction of a neuron? What is threshold activation function?"
      ],
      "metadata": {
        "id": "nb19eqkk6Y6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A summation junction of a neuron represents a weighted sum of the inputs to the neuron, where each input is multiplied by a corresponding weight value. The weighted sum represents the activation of the neuron, which is used to determine if the neuron should fire an output signal.\n",
        "\n",
        "- Threshold activation function is a non-linear function applied to the activation of a neuron to determine the output signal. It is commonly used in deep learning as an activation function for artificial neurons in artificial neural networks. The activation function maps the input activation to an output signal, typically between 0 and 1, and a threshold value is used to determine if the neuron should fire an output signal or not. For example, the threshold activation function could be the binary step function, where the output is 1 if the activation is above a certain threshold and 0 otherwise."
      ],
      "metadata": {
        "id": "jIyc6lBQ6fdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. What is a step function? What is the difference of step function with threshold function?"
      ],
      "metadata": {
        "id": "8wA3eR6I7BMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A step function is a type of threshold activation function that maps the input signal to a binary output signal. The step function outputs 1 if the input signal is above a certain threshold value, and 0 if the input signal is below that threshold.\n",
        "\n",
        "- The difference between a step function and a threshold function is that the step function only has two possible output values (0 or 1), whereas a threshold function can have multiple output values. The threshold function maps the input signal to a continuous output signal, rather than a binary one, based on the value of the input signal relative to the threshold. For example, the sigmoid activation function is a type of threshold function that maps the input signal to an output signal in the range of 0 to 1."
      ],
      "metadata": {
        "id": "Sgbr5WDD7M48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain the McCulloch–Pitts model of neuron."
      ],
      "metadata": {
        "id": "jldYWVfS7hAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The McCulloch-Pitts (M-P) model of a neuron is a mathematical model developed in 1943 that provides a simple, abstract representation of the functioning of a biological neuron. In this model, a neuron is viewed as a simple binary threshold device that can either be in an \"on\" or \"off\" state.\n",
        "\n",
        "- In the M-P model, each neuron receives inputs from other neurons, represented as binary values (0 or 1), which are then summed and passed through a threshold activation function. If the sum of the inputs exceeds a certain threshold, the neuron is activated and its output is set to 1, otherwise, the output is set to 0. The output of a neuron in the M-P model represents an action potential, or a signal transmitted from one neuron to another.\n",
        "\n",
        "- The M-P model was one of the first models to describe the functioning of a neuron as an information processing device, and it laid the foundation for the development of artificial neural networks. Despite its simplicity, the M-P model is still widely used today as a basic building block for more complex neural network models."
      ],
      "metadata": {
        "id": "DhB2NQUc7cXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Explain the ADALINE network model."
      ],
      "metadata": {
        "id": "wy3MeSjx7rcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ADALINE (Adaptive Linear Element) is a single-layer artificial neural network model developed in the late 1950s by Bernard Widrow and his colleagues at Stanford University. It is considered one of the earliest and simplest forms of a feedforward neural network.\n",
        "\n",
        "- The ADALINE network model consists of a single layer of artificial neurons, also known as \"processing elements\" or \"ADALINE neurons\". Each ADALINE neuron receives inputs from one or more external sources and performs a weighted sum of the inputs, similar to the McCulloch-Pitts model of a neuron. The weighted sum is then passed through an activation function, typically a linear activation function, to produce the output signal.\n",
        "\n",
        "- The ADALINE model uses a linear activation function, which maps the weighted sum of the inputs directly to the output signal. This makes the ADALINE network well-suited for linear regression and classification problems, where the relationship between the inputs and the outputs is linear.\n",
        "\n",
        "- The ADALINE network can be trained using supervised learning algorithms, such as the least mean squares (LMS) algorithm, to adjust the weights of the inputs and improve the accuracy of the network's predictions. This makes the ADALINE network useful for solving a wide range of problems, such as pattern recognition, function approximation, and system identification."
      ],
      "metadata": {
        "id": "BpiEF_J770Em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?"
      ],
      "metadata": {
        "id": "dmAKawHG77af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The simple perceptron is a type of artificial neural network model that was developed in the 1950s and is considered one of the earliest forms of machine learning. The constraint of a simple perceptron is that it can only solve linearly separable problems, meaning that the data can be separated into two classes by a single linear boundary.\n",
        "\n",
        "- The simple perceptron may fail with a real-world data set because many real-world data sets are not linearly separable. In these cases, the simple perceptron will not be able to learn the underlying relationship between the inputs and the outputs, and it will produce incorrect predictions.\n",
        "\n",
        "- In addition, the simple perceptron algorithm is prone to getting stuck in local minima, which means that the algorithm may converge to a suboptimal solution that is not the global minimum. This can also result in poor performance with real-world data sets.\n",
        "\n",
        "- To address these limitations, more advanced neural network models, such as multi-layer perceptrons (MLP) and convolutional neural networks (CNN), have been developed. These models can solve non-linearly separable problems and are less prone to getting stuck in local minima."
      ],
      "metadata": {
        "id": "yCbYO1KE9VFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. What is linearly inseparable problem? What is the role of the hidden layer?"
      ],
      "metadata": {
        "id": "IkV_MYX79cgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A linearly inseparable problem is a type of machine learning problem in which the data cannot be separated into two classes by a single linear boundary. This means that the relationship between the inputs and the outputs is non-linear and cannot be accurately modeled by a simple linear model, such as a single-layer perceptron.\n",
        "\n",
        "- The role of the hidden layer in artificial neural networks is to provide a non-linear transformation of the inputs, which enables the network to model more complex relationships between the inputs and the outputs. The hidden layer is located between the input layer and the output layer, and it consists of one or more artificial neurons that perform non-linear computations on the inputs.\n",
        "\n",
        "- By adding a hidden layer to the neural network, it is possible to model more complex non-linear relationships between the inputs and the outputs, which allows the network to solve linearly inseparable problems. The hidden layer acts as an intermediary, transforming the inputs into a higher-dimensional representation that is more suitable for classification or regression tasks.\n",
        "\n",
        "- In multi-layer perceptron (MLP) networks, multiple hidden layers can be used to provide a hierarchical representation of the inputs, which allows the network to model increasingly complex relationships between the inputs and the outputs. This makes MLP networks well-suited for solving a wide range of machine learning problems, including image classification, speech recognition, and natural language processing."
      ],
      "metadata": {
        "id": "3mGSSZ_u9tSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Explain XOR problem in case of a simple perceptron."
      ],
      "metadata": {
        "id": "rhRZv4-F9yav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The XOR (Exclusive OR) problem is a well-known example in the field of artificial neural networks that demonstrates the limitations of a simple perceptron model. The XOR problem involves binary classification, where the goal is to separate a set of points into two classes based on their XOR relationship.\n",
        "\n",
        "- In this problem, a simple perceptron is not able to separate the two classes by a single linear boundary, since the relationship between the inputs and the outputs is non-linear. This means that a simple perceptron will not be able to accurately model the XOR relationship and produce correct predictions.\n",
        "\n",
        "- For example, consider the following XOR table:\n",
        "\n",
        "Input 1 | Input 2 | Output\n",
        "\n",
        "0 | 0 | 0\n",
        "\n",
        "0 | 1 | 1\n",
        "\n",
        "1 | 0 | 1\n",
        "\n",
        "1 | 1 | 0\n",
        "\n",
        "- In this table, the inputs (Input 1 and Input 2) are binary values, and the output (Output) is the XOR relationship between the inputs. A simple perceptron will not be able to separate the points into two classes based on their XOR relationship, since the relationship between the inputs and the outputs is non-linear.\n",
        "\n",
        "- To solve the XOR problem with a simple perceptron, it is necessary to either add non-linear features to the inputs or to use a more advanced neural network model, such as a multi-layer perceptron (MLP) or a convolutional neural network (CNN). These models can model more complex non-linear relationships between the inputs and the outputs, which allows them to solve the XOR problem and produce correct predictions."
      ],
      "metadata": {
        "id": "wYOa-ILS-DZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Design a multi-layer perceptron to implement A XOR B."
      ],
      "metadata": {
        "id": "8C0Ic9no-QQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To design a multi-layer perceptron (MLP) to implement the XOR function, you would need to first preprocess the data to ensure that the inputs are numerical and have the correct format. You could then use an MLP with one or more hidden layers to model the non-linear relationship between the inputs and the outputs.\n",
        "\n",
        "- Below is an example implementation in Python using the Keras library:"
      ],
      "metadata": {
        "id": "lYajmpbW-lB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Define the derivative of the activation function\n",
        "def sigmoid_prime(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Create the training data\n",
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "outputs = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Define the model\n",
        "class XORModel:\n",
        "    def __init__(self):\n",
        "        self.weights1 = np.random.rand(2, 4)\n",
        "        self.weights2 = np.random.rand(4, 1)\n",
        "        self.bias1 = np.random.rand(4)\n",
        "        self.bias2 = np.random.rand(1)\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        layer1 = sigmoid(np.dot(inputs, self.weights1) + self.bias1)\n",
        "        layer2 = sigmoid(np.dot(layer1, self.weights2) + self.bias2)\n",
        "        return layer2\n",
        "\n",
        "model = XORModel()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    layer1 = sigmoid(np.dot(inputs, model.weights1) + model.bias1)\n",
        "    layer2 = sigmoid(np.dot(layer1, model.weights2) + model.bias2)\n",
        "    layer2_error = outputs - layer2\n",
        "    layer2_delta = layer2_error * sigmoid_prime(layer2)\n",
        "    layer1_error = layer2_delta.dot(model.weights2.T)\n",
        "    layer1_delta = layer1_error * sigmoid_prime(layer1)\n",
        "    model.weights2 += layer1.T.dot(layer2_delta)\n",
        "    model.weights1 += inputs.T.dot(layer1_delta)\n",
        "    model.bias2 += np.sum(layer2_delta, axis=0)\n",
        "    model.bias1 += np.sum(layer1_delta, axis=0)\n",
        "\n",
        "# Evaluate the model\n",
        "outputs_pred = model.predict(inputs)\n",
        "accuracy = np.sum((outputs_pred > 0.5) == outputs) / len(inputs)\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMetVGs_VxS",
        "outputId": "04e06f70-ce5b-49f3-a156-4b97463d583b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Explain the single-layer feed forward architecture of ANN."
      ],
      "metadata": {
        "id": "8uOZ8rsfAn7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The single-layer feed forward architecture of an Artificial Neural Network (ANN) refers to a type of neural network that consists of only one layer of output nodes connected to one or multiple layers of input nodes. The input nodes receive the inputs, process them, and then pass the result to the output nodes.\n",
        "\n",
        "- In a single-layer feed forward network, there are no loops or cycles. The information flows in a single direction from the input layer to the output layer, without any feedback. The activation function applied on the input signal in the output node determines the output of the network.\n",
        "\n",
        "- The single-layer feed forward architecture is simple, but limited in its capability to solve complex problems. For this reason, it is mostly used as the building block for deeper, more complex architectures like multilayer feed forward networks."
      ],
      "metadata": {
        "id": "DkdETUMYA4sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Explain the competitive network architecture of ANN."
      ],
      "metadata": {
        "id": "MCrpoSs1A87w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The competitive network architecture of an Artificial Neural Network (ANN) refers to a type of neural network where the nodes in the network are organized into several groups or clusters, with each group having a single node designated as the winner. The winner is the node with the highest activation value in response to the input signal.\n",
        "\n",
        "- In this architecture, the nodes in each group compete with each other to determine the winner. The winner node is then activated and its output value is set to 1, while the outputs of all other nodes in the same group are set to 0. This architecture is used to solve problems where the inputs have to be classified into a limited number of categories or clusters.\n",
        "\n",
        "- For example, if the input signals have to be classified into 4 categories, the network will have 4 groups of nodes, each group having a single node. The winner node of each group represents a category, and the activated node represents the category to which the input signal belongs.\n",
        "\n",
        "- Competitive network architecture is useful in image recognition, speech recognition, and pattern recognition problems, where the inputs have to be classified into a limited number of categories."
      ],
      "metadata": {
        "id": "wDEJ0dGQBMft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the backpropagation algorithm used to train the network."
      ],
      "metadata": {
        "id": "E1FJodh2BRE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The backpropagation algorithm is a supervised learning algorithm used to train multi-layer feed forward neural networks. The following are the steps involved in the backpropagation algorithm:\n",
        "\n",
        "    - Forward Propagation: During this step, the input data is fed into the network and the output values are computed at each node in the output layer. The activations are then propagated backwards through the network to the hidden layer.\n",
        "\n",
        "    - Error Computation: The difference between the actual output values and the target values is computed and the error is propagated backwards through the network to the hidden layer.\n",
        "\n",
        "    - Weight Update: The weights of the connections between the nodes are updated using gradient descent to minimize the error. This involves computing the gradient of the error with respect to the weights and then subtracting a small portion of this gradient from the current weights.\n",
        "\n",
        "    - Backward Propagation: The error is propagated backwards through the network from the output layer to the input layer.\n",
        "\n",
        "    - Repeat: The steps of forward propagation, error computation, gradient computation, and weight update are repeated multiple times until the network's performance on the training data is satisfactory. This process is referred to as an epoch. The algorithm continues for multiple epochs, each time updating the weights based on the error from the previous epoch, until a stopping criterion is met, such as a maximum number of epochs or a minimum error threshold.\n",
        "\n",
        "    - Gradient Computation: During backward propagation, the gradients of the error with respect to each weight are computed using the chain rule of calculus.\n",
        "\n",
        "    - Weight Update: The computed gradients are then used to update the weights of the connections between the nodes using gradient descent. The weights are updated according to the following equation:\n",
        "\n",
        "    w(t+1) = w(t) - η ∇E,\n",
        "\n",
        "    where w(t) is the weight at time step t, η is the learning rate, and ∇E is the gradient of the error with respect to the weight.\n",
        "\n",
        "    - Stopping Criteria: The backpropagation algorithm continues until a stopping criterion is met, such as a maximum number of iterations, or a minimum error threshold has been reached.\n",
        "\n",
        "    - Testing: After training is complete, the network is tested on a set of unseen data to evaluate its performance.\n",
        "\n",
        "    - Fine-tuning: If the network's performance is not satisfactory, the weights can be further fine-tuned by repeating the backpropagation algorithm with different learning rates, different activation functions, or different network architectures."
      ],
      "metadata": {
        "id": "V9jVGmpaB7h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. What are the advantages and disadvantages of neural networks?"
      ],
      "metadata": {
        "id": "vykAs1wyCXoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Advantages of Neural Networks:\n",
        "\n",
        "    - High Accuracy: Neural networks have the ability to model complex and non-linear relationships in data, leading to high accuracy in prediction and classification tasks.\n",
        "\n",
        "    - Generalization: Neural networks can generalize well to new unseen data, making them suitable for real-world problems where the data distribution may change over time.\n",
        "\n",
        "    - Handling Non-Linearity: Neural networks are well equipped to handle non-linear relationships between inputs and outputs, which is a common characteristic of real-world problems.\n",
        "\n",
        "    - Robustness: Neural networks are robust to missing and noisy input data, making them well suited for applications where data quality may be poor.\n",
        "\n",
        "    - Automated Feature Extraction: Neural networks can automatically extract features from raw input data, reducing the need for manual feature engineering.\n",
        "\n",
        "- Disadvantages of Neural Networks:\n",
        "\n",
        "    - Computational Complexity: Neural networks can require a large amount of computational resources, especially when training large datasets.\n",
        "\n",
        "    - Overfitting: Neural networks can easily overfit the training data, leading to poor performance on unseen data. This requires careful tuning of hyperparameters and regularization techniques to prevent overfitting.\n",
        "\n",
        "    - Black Box: Neural networks are often referred to as a \"black box\" due to their complex internal structure, making it difficult to interpret their decisions and understand how they arrive at their predictions.\n",
        "\n",
        "    - Initialization Sensitivity: Neural networks are sensitive to the initial values of the weights, which can greatly impact the final results. This requires careful initialization and tuning of the weights.\n",
        "\n",
        "    - Long Training Time: Training neural networks can be time-consuming, especially for large datasets and complex network architectures. This can be mitigated to some extent through parallelization and optimization techniques.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ILLoNk-FCkMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Write short notes on any two of the following:\n",
        "\n",
        "1. Biological neuron\n",
        "2. ReLU function\n",
        "3. Single-layer feed forward ANN\n",
        "4. Gradient descent\n",
        "5. Recurrent networks"
      ],
      "metadata": {
        "id": "E8tmhGTbCzlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Biological neuron:\n",
        "\n",
        "A biological neuron is a type of cell that is specialized for transmitting information in the nervous system. It has a cell body, dendrites (receive signals from other neurons), an axon (transmits signals to other neurons or muscles), and synapses (sites of communication between neurons). Neurons use electrical and chemical signals to transmit information, with the electrical signals traveling along the axon and chemical signals being transmitted across the synapses. This process allows neurons to communicate with each other and form complex neural networks that coordinate sensory information and control motor functions.\n",
        "\n",
        "## 2. ReLU function:\n",
        "The Rectified Linear Unit (ReLU) function is a commonly used activation function in artificial neural networks. It is defined as y = max(0,x), where x is the input and y is the output. The function returns 0 for negative values of x and x for positive values of x, creating a piecewise linear function. ReLU is popular due to its simplicity and ability to avoid the vanishing gradient problem that can occur with activation functions such as sigmoid and tanh. It also has a fast computation time as it only involves a simple comparison and multiplication operation.\n",
        "\n",
        "## 3. Single-layer feed forward ANN:\n",
        "\n",
        "A single-layer feedforward artificial neural network (ANN) is a simple type of artificial neural network that consists of only one layer of neurons (also called perceptrons) connected in a feedforward manner, meaning the information flows in only one direction, from input to output, without forming a loop. This layer is called the output layer, and the neurons in this layer are responsible for producing the final output of the network. The input layer takes the raw data, and the output layer produces the predicted outcome. The single-layer feedforward ANN is trained using an optimization algorithm, such as gradient descent, to adjust the weights of the connections between the input and output layer neurons so as to minimize the difference between the predicted and actual output. Despite its simplicity, a single-layer feedforward ANN can be effective for solving certain types of problems, especially if the number of neurons in the output layer is sufficient to capture the complexity of the problem.\n",
        "\n",
        "## 4. Gradient descent:\n",
        "\n",
        "Gradient descent is an optimization algorithm used to minimize a loss function in machine learning and deep learning. The algorithm iteratively updates the parameters of a model in the direction of the negative gradient of the loss function with respect to the parameters, with the goal of finding the set of parameters that produce the lowest possible value of the loss function. The magnitude of the update is determined by the learning rate, which controls the step size of each iteration. Gradient descent is a first-order optimization method and is widely used due to its simplicity and effectiveness in practice. There are several variants of gradient descent, including batch gradient descent, stochastic gradient descent, and mini-batch gradient descent, which differ in how the loss is computed and averaged over the training examples.\n",
        "\n",
        "## 5. Recurrent networks:\n",
        "\n",
        "Recurrent neural networks (RNNs) are a type of artificial neural network designed to process sequential data, such as time series, text, speech, or video. Unlike feedforward neural networks, RNNs have a feedback loop, which allows information to persist from one step of the sequence to the next. This enables RNNs to capture temporal dependencies and patterns in the input data. RNNs can be unrolled over time to form a chain-like structure, where each node in the chain represents the hidden state of the network at a given time step. The hidden state is updated at each time step based on the current input and the hidden state from the previous time step. RNNs can also be stacked to form deeper networks, such as deep RNNs or long short-term memory (LSTM) networks, which are more powerful in capturing longer term dependencies in the data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTcU8GccC3Pu"
      }
    }
  ]
}